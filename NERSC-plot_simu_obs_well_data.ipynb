{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:27:30.377690Z",
     "start_time": "2018-06-29T17:27:30.371179Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import simulation output and observation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:27:33.714188Z",
     "start_time": "2018-06-29T17:27:32.308932Z"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# import glob, datetime, ipdb, pickle, pyproj, json, mplleaflet, geopandas, fiona, sys, cartopy, \\\n",
    "#          math, folium, base64\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "import matplotlib \n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import pandas as pd\n",
    "import ipywidgets as ipyw\n",
    "# import cartopy.crs as ccrs\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from datetime import timedelta\n",
    "from scipy import interpolate\n",
    "# from ipyleaflet import *\n",
    "# from geojson import Feature, FeatureCollection, Point\n",
    "# from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from natsort import natsorted, ns, natsort_keygen\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "# from folium.plugins import FloatImage\n",
    "# from folium import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:27:50.517868Z",
     "start_time": "2018-06-29T17:27:50.503531Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def batch_delta_to_time(origin, x, time_format, delta_format):\n",
    "    y = []\n",
    "    for ix in x:\n",
    "        if delta_format == \"hours\":\n",
    "            temp_y = origin + timedelta(hours=ix)\n",
    "        elif delta_format == \"days\":\n",
    "            temp_y = origin + timedelta(days=ix)\n",
    "        elif delta_format == \"minutes\":\n",
    "            temp_y = origin + timedelta(minutes=ix)\n",
    "        elif delta_format == \"weeks\":\n",
    "            temp_y = origin + timedelta(weeks=ix)\n",
    "        elif delta_format == \"seconds\":\n",
    "            temp_y = origin + timedelta(seconds=ix)\n",
    "        elif delta_format == \"microseconds\":\n",
    "            temp_y = origin + timedelta(microseconds=ix)\n",
    "        elif delta_format == \"milliseconds\":\n",
    "            temp_y = origin + timedelta(milliseconds=ix)\n",
    "        else:\n",
    "            print(\"Sorry, this naive program only solve single time unit\")\n",
    "        y.append(temp_y.strftime(time_format))\n",
    "    y = np.asarray(y)\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T23:11:19.773596Z",
     "start_time": "2018-05-18T23:11:19.771637Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print both group and its member names\n",
    "def printname(name):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O files and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:39:15.838248Z",
     "start_time": "2018-07-06T19:39:15.786645Z"
    }
   },
   "outputs": [],
   "source": [
    "#=======================input==========================\n",
    "case_name = \"HFR_model_100x100x2_new_iniH/\"\n",
    "\n",
    "model_dir = \"/global/cscratch1/sd/pshuai/\" + case_name\n",
    "\n",
    "fname_model_origin = model_dir + \"model_origin.txt\"\n",
    "fname_material_h5 = model_dir + \"HFR_material_river.h5\"\n",
    "fname_pflotran_h5 = model_dir + \"pflotran_200x200x2_6h_bc_obs.h5\"\n",
    "\n",
    "# fname_300A_h5 = \"/Users/shua784/Paraview/300A/John_case_optim_5/pflotran_bigplume-004.h5\"\n",
    "fname_tec_files = model_dir + \"obs_wells/*.tec\"\n",
    "\n",
    "data_dir = \"/global/project/projectdirs/m1800/pin/Reach_scale_model/data/\"\n",
    "\n",
    "fname_mass1_coord = data_dir + \"MASS1/coordinates.csv\"\n",
    "fname_mass1_data = data_dir + 'MASS1/transient_1976_2016/'\n",
    "fname_300A_well_screen = data_dir + \"well_data/300A_Monitoring_Well_Screen.csv\"\n",
    "fname_300A_well_data = data_dir + 'well_data/SFA_all_wells.csv'\n",
    "fname_300A_well_ID = data_dir + 'well_data/300A_well_coord.csv'\n",
    "fname_300A_spc_u = data_dir + 'well_data/Sample_Data_2015_U.csv'\n",
    "fname_HEIS_well_screen = data_dir + 'well_data/wellCasingAndScreen.csv'\n",
    "fname_HEIS_300A_screen = data_dir + 'well_data/HEIS_300A_well_screen.csv'\n",
    "fname_HEIS_auto_well = data_dir + 'well_data/mvAwln.csv'\n",
    "fname_HEIS_auto_wellID = data_dir + 'well_data/mvAwln_wellID_updated.csv'\n",
    "fname_HEIS_manual_well = data_dir + 'well_data/HYDRAULIC_HEAD_MV.csv'\n",
    "fname_HEIS_manual_wellID = data_dir + 'well_data/HYDRAULIC_HEAD_MV_WellID.csv'\n",
    "fname_GW_chem = data_dir + 'well_data/GW_SAMPLE_RESULT_MV.csv'\n",
    "fname_river_geo = data_dir + 'river_geometry_manual_v2.csv'\n",
    "fname_USGS_well = data_dir + 'well_data/Burns_well_data.csv'\n",
    "fname_USGS_attr = data_dir + 'well_data/Burns_well_attributes.csv'\n",
    "\n",
    "fname_GW_U_summary = data_dir + 'well_data/GW_chemistry/Uranium_summary.csv'\n",
    "fname_GW_Cr_summary = data_dir + 'well_data/GW_chemistry/Chromium_summary.csv'\n",
    "fname_GW_As_summary = data_dir + 'well_data/GW_chemistry/Arsenic_summary.csv'\n",
    "fname_GW_spc_summary = data_dir + 'well_data/GW_chemistry/Specific Conductance_summary.csv'\n",
    "fname_GW_NO3_summary = data_dir + 'well_data/GW_chemistry/Nitrate_summary.csv'\n",
    "# GeoJson file\n",
    "fname_GW_NO3_geojson = data_dir + 'well_data/GW_chemistry/Nitrate_geojson.json'\n",
    "fname_hanford_shp = '/Users/shua784/Dropbox/PNNL/Projects/Columbia_Basin/Reach domain_QGIS/bvjursd.shp'\n",
    "\n",
    "fname_ichemical_csv = data_dir + 'well_data/GW_chemistry/'\n",
    "fname_river_bc_6h = \"/Users/shua784/Dropbox/PNNL/Projects/Reach_scale_model/Inputs/river_bc/bc_6h_smooth_032807/\"\n",
    "\n",
    "fname_selected_wells_csv = \"/Users/shua784/Dropbox/PNNL/Projects/Reach_scale_model/results/selected_wells_unique_010107_3m.csv\"\n",
    "#============================output==========================\n",
    "out_dir = \"/global/project/projectdirs/m1800/pin/Reach_scale_model/Outputs/\" + case_name\n",
    "\n",
    "fig_wl = out_dir + 'wl/'\n",
    "fig_simu_obs_wl = out_dir + \"simu_obs_wl/\"\n",
    "fig_obs_head = out_dir + \"obs_head/\"\n",
    "fig_tracer_spc = out_dir + \"tracer_spc/\"\n",
    "fig_tracer_nitrate = out_dir + \"tracer_nitrate/\"\n",
    "fig_tracer_cr = out_dir + 'tracer_cr/'\n",
    "fig_tracer_U = out_dir + 'tracer_U/'\n",
    "fig_tracer_NO3 = out_dir + \"tracer_nitrate/\"\n",
    "\n",
    "result_dir = \"/global/project/projectdirs/m1800/pin/Reach_scale_model/results/\" + case_name\n",
    "\n",
    "fname_well_simu_data_pk = result_dir + \"well_simu_data.p\"\n",
    "fname_simu_data_df_pickle = result_dir + 'simu_data_df.p'\n",
    "fname_well_data_df_pickle = result_dir + 'well_data_df.p'\n",
    "fname_selected_wells_pickle = result_dir + 'selected_wells_for_folium.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T18:53:14.640490Z",
     "start_time": "2018-07-02T18:53:14.629109Z"
    }
   },
   "outputs": [],
   "source": [
    "P_atm = 101325\n",
    "rho = 997.16\n",
    "g_const = 9.81\n",
    "\n",
    "z_bot = 0\n",
    "z_top = 200\n",
    "\n",
    "xlen = 60*1000\n",
    "ylen = 60*1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:32:00.986079Z",
     "start_time": "2018-06-29T17:32:00.976979Z"
    }
   },
   "outputs": [],
   "source": [
    "date_origin = datetime.datetime.strptime(\"2007-03-28 12:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "# read model origin\n",
    "# model_origin = np.genfromtxt(fname_model_origin, delimiter=\" \", skip_header=1)\n",
    "model_origin = [551600, 104500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import well data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import well screen/coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**combine 300A well screen with HEIS well screen data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:53:29.116640Z",
     "start_time": "2018-06-29T17:53:29.098721Z"
    }
   },
   "outputs": [],
   "source": [
    "screen_300A = pd.read_csv(fname_300A_well_screen, index_col=['Well_ID'])\n",
    "screen_HEIS = pd.read_csv(fname_HEIS_well_screen, index_col=['Well_ID'])\n",
    "\n",
    "screen_HEIS_copy = screen_HEIS[['WellName', 'EASTING', 'NORTHING', 'TopCasing', 'TopScreen', 'BottomScreen']]\n",
    "# rename columns\n",
    "screen_HEIS_copy.columns = ['WellName', 'Easting', 'Northing', 'CASING_ELEVATION', 'SCREEN_ELEV_TOP', 'SCREEN_ELEV_BOTTOM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** filter out wells without screen information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T18:33:07.547921Z",
     "start_time": "2018-06-22T18:33:07.348243Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove duplicates and NaN\n",
    "screen_300A_HEIS = screen_300A.append(screen_HEIS_copy).drop_duplicates('WellName', keep='first') \\\n",
    "                                .dropna(subset=['SCREEN_ELEV_TOP', 'SCREEN_ELEV_BOTTOM']) \\\n",
    "                                .sort_values(by = 'index')\n",
    "# save to csv file\n",
    "screen_300A_HEIS.to_csv(fname_HEIS_300A_screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:32:22.123497Z",
     "start_time": "2018-06-29T17:32:22.112400Z"
    }
   },
   "outputs": [],
   "source": [
    "screen_300A_HEIS = pd.read_csv(fname_HEIS_300A_screen, index_col=['WellName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T23:32:11.805745Z",
     "start_time": "2018-06-08T23:32:11.788578Z"
    }
   },
   "outputs": [],
   "source": [
    "# well_screen = well_screen.copy()\n",
    "well_screen = pd.read_csv(fname_HEIS_300A_screen, index_col= ['WellName'])\n",
    "\n",
    "well_screen['Easting'] = well_screen['Easting'] - model_origin[0]\n",
    "well_screen['Northing'] = well_screen['Northing'] - model_origin[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**combine 300A/HEIS/USGS coord **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:32:30.509723Z",
     "start_time": "2018-06-29T17:32:30.316836Z"
    }
   },
   "outputs": [],
   "source": [
    "USGS_well_attr = pd.read_csv(fname_USGS_attr, dtype={'CP_ID_NUM':np.int64})\n",
    "USGS_well_attr.rename(columns={'CP_ID':'WellName','CP_ID_NUM':'Well_ID', 'X_SP_83FT':'Easting', \\\n",
    "                               'Y_SP_83FT':'Northing'}, inplace = True)\n",
    "USGS_well_attr['Well_ID'] = USGS_well_attr['Well_ID'].apply(str)\n",
    "USGS_well_attr['Easting'] = USGS_well_attr['Easting']*0.3048\n",
    "USGS_well_attr['Northing'] = USGS_well_attr['Northing']*0.3048\n",
    "USGS_well_attr.set_index('WellName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:44:03.442028Z",
     "start_time": "2018-06-29T17:44:03.430995Z"
    }
   },
   "outputs": [],
   "source": [
    "screen_300A_HEIS_sub = screen_300A_HEIS[['Well_ID', 'Easting', 'Northing']]\n",
    "\n",
    "USGS_well_attr_sub = USGS_well_attr[['Well_ID', 'Easting', 'Northing']]\n",
    "\n",
    "USGS_well_attr_sub = USGS_well_attr_sub[(USGS_well_attr_sub['Easting'] <= model_origin[0] + xlen) & (USGS_well_attr_sub['Easting'] >= model_origin[0])\\\n",
    "                                           & (USGS_well_attr_sub['Northing'] <= model_origin[1] + ylen) & (USGS_well_attr_sub['Northing'] >= model_origin[1])]\n",
    "\n",
    "coord_300A_HEIS_USGS = screen_300A_HEIS_sub.append(USGS_well_attr_sub).dropna().\\\n",
    "                        drop_duplicates(subset = ['Easting', 'Northing'], keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import well ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T17:48:08.557074Z",
     "start_time": "2018-07-05T17:48:08.546777Z"
    }
   },
   "outputs": [],
   "source": [
    "wellID_300A = pd.read_csv(fname_300A_well_ID)\n",
    "wellID_300A.rename(columns = {'wells':'WellName'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T18:20:38.101791Z",
     "start_time": "2018-07-05T18:20:38.092808Z"
    }
   },
   "outputs": [],
   "source": [
    "wellID_300A.set_index('WellName', inplace=True)\n",
    "wellID_300A_sub = wellID_300A[['Easting', 'Northing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T19:12:13.787533Z",
     "start_time": "2018-07-02T19:12:13.776238Z"
    }
   },
   "outputs": [],
   "source": [
    "HEIS_manual_wellID = pd.read_csv(fname_HEIS_manual_wellID, dtype={'EASTING':np.float64, 'NORTHING':np.float64})\n",
    "HEIS_manual_wellID.rename(columns = {'WELL_ID':'Well_ID', 'WELL_NAME':'WellName', 'NORTHING':'Northing', 'EASTING':'Easting'}, \\\n",
    "                         inplace = True)\n",
    "HEIS_manual_wellID.set_index('WellName', inplace=True)\n",
    "HEIS_manual_wellID_sub = HEIS_manual_wellID[['Well_ID', 'Easting', 'Northing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T19:18:08.309602Z",
     "start_time": "2018-07-02T19:18:08.302179Z"
    }
   },
   "outputs": [],
   "source": [
    "HEIS_auto_wellID = pd.read_csv(fname_HEIS_auto_wellID, na_values=['#REF!'], dtype={'Easting':np.float64, 'Northing':np.float64})\n",
    "HEIS_auto_wellID.rename(columns = {'WellNumber':'Well_ID'}, inplace = True)\n",
    "HEIS_auto_wellID.set_index('WellName', inplace=True)\n",
    "HEIS_auto_wellID_sub = HEIS_auto_wellID[['Well_ID', 'Easting', 'Northing']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** store all well ids within domian **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T19:29:54.047475Z",
     "start_time": "2018-07-02T19:29:54.040282Z"
    }
   },
   "outputs": [],
   "source": [
    "All_well_coord = HEIS_manual_wellID_sub.append([wellID_300A_sub, HEIS_auto_wellID_sub, USGS_well_attr_sub]).dropna()\n",
    "\n",
    "All_well_coord = All_well_coord[~All_well_coord.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T19:30:01.108812Z",
     "start_time": "2018-07-02T19:30:00.804889Z"
    }
   },
   "outputs": [],
   "source": [
    "All_well_coord['Easting_rint'] = np.rint(All_well_coord['Easting'])\n",
    "All_well_coord['Northing_rint'] = np.rint(All_well_coord['Northing'])\n",
    "\n",
    "All_well_coord = All_well_coord.drop_duplicates(subset = ['Easting_rint', 'Northing_rint'],keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import well obs data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import well water level data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:33:00.628519Z",
     "start_time": "2018-06-29T17:32:51.572478Z"
    }
   },
   "outputs": [],
   "source": [
    "# import obs well data\n",
    "SFA_well = pd.read_csv(fname_300A_well_data, parse_dates=['DateTime'])\n",
    "# SFA_well['DateTime'] = SFA_well['DateTime'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:33:23.693820Z",
     "start_time": "2018-06-29T17:33:04.404850Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(well_data.head(5))\n",
    "HEIS_auto = pd.read_csv(fname_HEIS_auto_well, parse_dates=['procDate'])\n",
    "HEIS_manual = pd.read_csv(fname_HEIS_manual_well, parse_dates=['HYD_DATE_TIME_PST'])\n",
    "\n",
    "## rename column names to contain the following label : **Well_ID, WellName, DateTime, WL**\n",
    "HEIS_manual.rename(columns={'WELL_ID':'Well_ID', 'WELL_NAME': 'WellName', 'HYD_DATE_TIME_PST':'DateTime', \\\n",
    "                           'HYD_HEAD_METERS_NAVD88':'WL'}, inplace = True)\n",
    "HEIS_auto.rename(columns={'WellNumber':'Well_ID', 'procWaterElevation':'WL', 'procDate':'DateTime'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:33:46.192953Z",
     "start_time": "2018-06-29T17:33:45.048243Z"
    }
   },
   "outputs": [],
   "source": [
    "USGS_well = pd.read_csv(fname_USGS_well, parse_dates=['DATE'])\n",
    "USGS_well.rename(columns={'CP_NUM': 'WellID', 'DATE':'DateTime', \\\n",
    "                           'WLELEVft88':'WL'}, inplace = True)\n",
    "# USGS_well['DateTime'] = USGS_well['DateTime'].apply(pd.to_datetime)\n",
    "USGS_well['WellName'] = ['CP' + str(x).zfill(6) for x in USGS_well['WellID']]\n",
    "USGS_well['WL'] = USGS_well['WL']*0.3048  # convert ft to m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import groudwater chemistry data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc_u_data = pd.read_csv(fname_300A_spc_u)\n",
    "spc_u_data.rename(columns={'well ID':'WellName', 'date/time':'DateTime', 'Temp(degrees C)':'Temp', \\\n",
    "                           'SpC(uS/cm)':'Spc', 'U (ug/L)':'U'}  , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T18:51:56.218946Z",
     "start_time": "2018-06-21T18:48:59.506289Z"
    }
   },
   "outputs": [],
   "source": [
    "# import groundwater chemistry data\n",
    "GW_chem = pd.read_csv(fname_GW_chem)\n",
    "\n",
    "GW_chem.rename(columns={'SAMP_DATE_TIME': 'DateTime', 'STD_CON_LONG_NAME':'Chemical', \\\n",
    "                        'STD_VALUE_RPTD':'Concentration', 'STD_ANAL_UNITS_RPTD':'Unit', \\\n",
    "                       'SAMP_SITE_NAME': 'WellName', 'SAMP_SITE_ID':'Well_ID'}, inplace=True)\n",
    "\n",
    "GW_chem['DateTime'] = GW_chem['DateTime'].apply(pd.to_datetime)\n",
    "\n",
    "# # split one column to two separate columns\n",
    "# GW_chem['WellName'] = GW_chem['WellName_ID'].str.split('[()]').str[0]\n",
    "# GW_chem['Well_ID']= GW_chem['WellName_ID'].str.split('[()]').str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export selected chemicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T05:07:51.725905Z",
     "start_time": "2018-05-21T05:07:27.681148Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chemicals = list(GW_chem.Chemical.unique())\n",
    "chemicals.sort()\n",
    "\n",
    "selected_chemicals = ['Specific Conductance', 'pH Measurement', 'Temperature', 'Nitrate', \\\n",
    "                     'Chromium', 'Turbidity', 'Nitrite', 'Arsenic', 'Uranium']\n",
    "\n",
    "# save each chemical as file\n",
    "for ichemical in selected_chemicals[:]:\n",
    "    table = GW_chem[GW_chem.loc[:,'Chemical'] == ichemical].copy()\n",
    "    \n",
    "    if '/' in ichemical:\n",
    "        fname = data_dir + 'well_data/GW_chemistry/' + ichemical.replace('/',' ') + '.csv'\n",
    "    else:\n",
    "        fname = data_dir + 'well_data/GW_chemistry/' + ichemical + '.csv'\n",
    "    \n",
    "    table.to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import mass1 coordicates data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T23:41:46.358484Z",
     "start_time": "2018-06-08T23:41:46.341450Z"
    }
   },
   "outputs": [],
   "source": [
    "# read mass1 coordinates\n",
    "section_coord = np.genfromtxt(\n",
    "    fname_mass1_coord, delimiter=\",\", skip_header=1)\n",
    "section_coord[:, 1] = section_coord[:, 1] - model_origin[0]\n",
    "section_coord[:, 2] = section_coord[:, 2] - model_origin[1]\n",
    "line1 = section_coord[0, 1:3] / 1000\n",
    "line2 = section_coord[int(len(section_coord[:, 1]) / 2), 1:3] / 1000\n",
    "line3 = section_coord[-1, 1:3] / 1000\n",
    "\n",
    "line1_x = [line1[0]] * 2\n",
    "line1_y = [line1[1] - 5, line1[1] + 5]\n",
    "line2_x = [line2[0] - 5, line2[0] + 5]\n",
    "line2_y = [line2[1]] * 2\n",
    "line3_x = [line3[0] - 5, line3[0] + 5]\n",
    "line3_y = [line3[1]] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T18:05:09.106946Z",
     "start_time": "2018-06-29T18:05:09.096829Z"
    }
   },
   "outputs": [],
   "source": [
    "mass1_coord = pd.read_csv(fname_mass1_coord)\n",
    "mass1_coord.rename(columns={'quadrant': 'Mass_ID', 'easting':'Easting', \\\n",
    "                        'northing':'Northing'}, inplace=True)\n",
    "mass1_coord['Easting'] = mass1_coord['Easting'] - model_origin[0]\n",
    "mass1_coord['Northing'] = mass1_coord['Northing'] - model_origin[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read model dim, time index from hdf5 output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T18:05:19.830538Z",
     "start_time": "2018-06-29T18:05:16.176678Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_h5 = glob.glob(fname_pflotran_h5) # find all \"pflotran*.h5\" files\n",
    "# all_h5 = np.sort(all_h5)\n",
    "\n",
    "input_h5 = h5.File(fname_pflotran_h5, \"r\")\n",
    "\n",
    "# input_h5.visit(printname)\n",
    "\n",
    "x_grids = list(input_h5[\"Coordinates\"]['X [m]'])\n",
    "y_grids = list(input_h5[\"Coordinates\"]['Y [m]'])\n",
    "z_grids = list(input_h5[\"Coordinates\"]['Z [m]'])\n",
    "# input_h5.close()\n",
    "\n",
    "dx = np.diff(x_grids)\n",
    "dy = np.diff(y_grids)\n",
    "dz = np.diff(z_grids)\n",
    "\n",
    "nx = len(dx)\n",
    "ny = len(dy)\n",
    "nz = len(dz)\n",
    "\n",
    "# x,y,z coordinates at cell center\n",
    "x = x_grids[0] + np.cumsum(dx) - 0.5 * dx[0]\n",
    "y = y_grids[0] + np.cumsum(dy) - 0.5 * dy[0]\n",
    "z = z_grids[0] + np.cumsum(dz) - 0.5 * dz[0]\n",
    "\n",
    "# generate mesh grid\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "# create grids (nx*ny*nz, 3)--a list of arrays based nx, ny, nz\n",
    "grids = np.asarray([(x, y, z) for z in range(nz)\n",
    "                    for y in range(ny) for x in range(nx)])\n",
    "\n",
    "groups = list(input_h5.keys()) # create a list with group names\n",
    "time_index = [s for s, s in enumerate(groups) if \"Time:\" in s] # enumerate returns its index (index, string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find location of cell based on cellid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T00:17:07.573109Z",
     "start_time": "2018-06-22T00:17:07.569802Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grids, columns = ['x', 'y', 'z'])\n",
    "\n",
    "def cell_id_to_xyz(cell_id):\n",
    "    xyz = df.iloc[cell_id - 1, :] \n",
    "    print('x loc is:{}, y loc is:{}, z loc is:{}'.format(xyz.x+1, xyz.y+1, xyz.z+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T00:17:50.503478Z",
     "start_time": "2018-06-22T00:17:50.501063Z"
    }
   },
   "outputs": [],
   "source": [
    "cell_id_to_xyz(89980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T18:34:17.640261Z",
     "start_time": "2018-06-22T18:34:17.629385Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_time_index = []\n",
    "for itime in np.arange(len(time_index)):\n",
    "    itime_str = list(batch_delta_to_time(date_origin, [float(time_index[itime][7:18])], \"%Y-%m-%d %H:%M:%S\", \"hours\"))\n",
    "    itime_str = ''.join(itime_str)\n",
    "    real_time_index.append(datetime.datetime.strptime(itime_str, \"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read river cell information from material h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T22:13:28.941530Z",
     "start_time": "2018-06-20T22:13:27.379269Z"
    }
   },
   "outputs": [],
   "source": [
    "# open file for reading\n",
    "material_h5 = h5.File(fname_material_h5, \"r\") \n",
    "# read river cell ids\n",
    "river_cells = []\n",
    "for i_region in list(material_h5['Regions'].keys()):\n",
    "    river_cells = np.append(river_cells, np.asarray(\n",
    "        list(material_h5[\"Regions\"][i_region][\"Cell Ids\"])))\n",
    "river_cells = np.unique(river_cells).astype(int)\n",
    "river_cells = river_cells - 1  # need minus 1 as python index started with 0\n",
    "# label river cells in x-y plane with '1'\n",
    "yx_river = np.asarray([np.nan] * (ny * nx)).reshape(ny, nx) # initialize ny*nx array with nan value, because python read column first (y,x)\n",
    "for icell in river_cells:\n",
    "    yx_river[grids[icell, 1], grids[icell, 0]] = 1\n",
    "    \n",
    "material_h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot well obs head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T20:38:44.318435Z",
     "start_time": "2018-07-02T20:38:44.316339Z"
    }
   },
   "outputs": [],
   "source": [
    "# selected_wells_iniH = pd.read_csv(fname_selected_wells_csv, index_col='WellName')\n",
    "# coord_300A_HEIS_USGS = selected_wells_iniH\n",
    "coord_300A_HEIS_USGS = All_well_coord\n",
    "selected_wells = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T12:28:54.518084Z",
     "start_time": "2018-07-04T00:48:52.261639Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline \n",
    "\n",
    "for iwell in coord_300A_HEIS_USGS.index[2235:]:\n",
    "#     iwell = '299-W15-9'\n",
    "    print(iwell)\n",
    "    # read obs.head\n",
    "    if iwell in SFA_well['WellName'].unique():\n",
    "        iobs_head_df = SFA_well[ SFA_well.loc[:, 'WellName'] == iwell].copy()\n",
    "\n",
    "    elif iwell in HEIS_auto['WellName'].unique():\n",
    "        iobs_head_df = HEIS_auto[ HEIS_auto.loc[:, 'WellName'] == iwell].copy()\n",
    "\n",
    "    elif iwell in HEIS_manual['WellName'].unique():\n",
    "        iobs_head_df = HEIS_manual[ HEIS_manual.loc[:, 'WellName'] == iwell].copy()\n",
    "        \n",
    "    elif iwell in USGS_well['WellName'].unique():\n",
    "        iobs_head_df = USGS_well[ USGS_well.loc[:, 'WellName'] == iwell].copy()\n",
    "\n",
    "    else:\n",
    "        iobs_head_df = pd.DataFrame()\n",
    "        print('No well obs data available for' + iwell)\n",
    "        continue\n",
    "   \n",
    "    #     iobs_head_df['DateTime'] = iobs_head_df['DateTime'].apply(pd.to_datetime)\n",
    "    iobs_head_df = iobs_head_df.drop_duplicates('DateTime', keep='first') \\\n",
    "                                .dropna(subset = ['DateTime', 'WL']).set_index('DateTime', drop=False).sort_index()\n",
    "    # filter wells outside of dates\n",
    "#     iobs_head_df = iobs_head_df[(iobs_head_df['DateTime'] >= datetime.date(2005, 1, 1)) \\\n",
    "#                                 & (iobs_head_df['DateTime'] <= datetime.date(2018, 1, 1))]\n",
    "    \n",
    "    if iobs_head_df['WL'].count() > 1 :   \n",
    "        selected_wells.append(iwell)\n",
    "        \n",
    "        # get stat for well\n",
    "        istat = iobs_head_df.WL.describe()\n",
    "        coord_300A_HEIS_USGS.loc[iwell, 'min'] = istat['min']\n",
    "        coord_300A_HEIS_USGS.loc[iwell, 'max'] = istat['max']\n",
    "        coord_300A_HEIS_USGS.loc[iwell, 'mean'] = istat['mean']\n",
    "        coord_300A_HEIS_USGS.loc[iwell, 'median'] = istat['50%']\n",
    "        coord_300A_HEIS_USGS.loc[iwell, 'count'] = istat['count']\n",
    "                \n",
    "        # find closest mass1 location\n",
    "        iwell_easting = coord_300A_HEIS_USGS.loc[iwell, 'Easting'] - model_origin[0]\n",
    "        iwell_northing = coord_300A_HEIS_USGS.loc[iwell, 'Northing'] - model_origin[1]\n",
    "        dist = np.sqrt((mass1_coord['Easting']- iwell_easting)**2 + (mass1_coord['Northing']- iwell_northing)**2)\n",
    "        mass_id = mass1_coord.loc[np.argmin(dist), 'Mass_ID']\n",
    "\n",
    "        mass1_datum_files = glob.glob(fname_mass1_data + \"mass1*.csv\")\n",
    "        mass1_datum_files = natsorted(mass1_datum_files) \n",
    "\n",
    "        for ifile in mass1_datum_files:\n",
    "            if '_' + str(mass_id) in ifile:\n",
    "                river_stage = pd.read_csv(ifile, parse_dates=['date']).dropna()\n",
    "            elif mass_id == 333:\n",
    "                river_stage = pd.read_csv(mass1_datum_files[-1],  parse_dates=['date']).dropna()\n",
    "\n",
    "        river_stage['stage'] = river_stage['stage'] + 1.039 \n",
    "        \n",
    "        # find the mode of frequecy (in sec)\n",
    "        res = iobs_head_df['DateTime'].diff().dt.seconds.value_counts().index[0]\n",
    "        val = iobs_head_df['DateTime'].diff().dt.seconds.value_counts().values[0]\n",
    "        if res <= 86400 and val >=100 :    \n",
    "            style = '-k'\n",
    "        else:\n",
    "            style = '-ko'\n",
    "        \n",
    "        ##================= plot simu vs obs head========================##\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(2,1,1)\n",
    "\n",
    "        river_stage.plot(x= 'date', y= 'stage', legend=False, ax=ax1, color = 'gray' , lw = 1, rot = 0, alpha = 0.5)\n",
    "\n",
    "        ax1.set_ylabel('River stage (m)')\n",
    "        ax2 = fig.add_subplot(2,1,2, sharex = ax1)\n",
    "        iobs_head_df.plot(x= 'DateTime', y= 'WL', legend=False, ax=ax2, style=style ,\\\n",
    "                          markerfacecolor = \"None\", ms = 3, lw = 1, rot = 0)\n",
    "\n",
    "    \n",
    "        ax1.set_title('Well ' + iwell,  fontweight = 'bold', fontsize = 14)\n",
    "        # format the ticks\n",
    "#         ax2.xaxis.set_major_locator(mdates.YearLocator())\n",
    "#         ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "#         ax2.xaxis.set_tick_params('labelbottom')\n",
    "        \n",
    "#         ax.set_xlim([real_time_6h[0], real_time_6h[-1]])\n",
    "#         ax.set_ylim([104.5, 108.5])\n",
    "        ax2.set_ylabel('Water Level (m)')\n",
    "        ax2.set_xlabel('')\n",
    "        \n",
    "        plt.minorticks_off()\n",
    "        fig.tight_layout()\n",
    "        fig.set_size_inches(8, 5)\n",
    "        fname = fig_obs_head + 'Well ' + iwell\n",
    "        fig.savefig(fname , dpi=100)\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T18:34:27.168151Z",
     "start_time": "2018-07-05T18:34:27.124515Z"
    }
   },
   "outputs": [],
   "source": [
    "coord_300A_HEIS_USGS.to_csv(data_dir + \"well_data/All_well_coord.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T18:20:24.909545Z",
     "start_time": "2018-06-25T18:20:24.901251Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(fname_selected_wells_pickle, 'wb') as f:\n",
    "    pickle.dump(selected_wells, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interactive map with folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: some wells ('399-1-32', '399-1-60', '399-2-10', '399-2-25', '399-2-33', '399-3-26',\n",
    "       '399-3-29', '399-3-37', 'NRG', 'SWS-1') in the 300A area has not been included in the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T22:38:08.299368Z",
     "start_time": "2018-06-25T22:38:08.290365Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(fname_selected_wells_pickle, \"rb\") as f:\n",
    "#     selected_wells = pickle.load(f)\n",
    "\n",
    "# selected_wells_df = coord_300A_HEIS_USGS.loc[selected_wells, :]\n",
    "\n",
    "# selected_wells_df['Easting_rint'] = np.rint(selected_wells_df['Easting'])\n",
    "# selected_wells_df['Northing_rint'] = np.rint(selected_wells_df['Northing'])\n",
    "\n",
    "# selected_wells_df.drop_duplicates(subset = ['Easting_rint', 'Northing_rint'],keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T18:56:17.456077Z",
     "start_time": "2018-07-05T18:56:17.452208Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_wells_df = coord_300A_HEIS_USGS.copy().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T20:02:40.395918Z",
     "start_time": "2018-07-05T20:02:40.392528Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_wells_df.drop(['299-W15-9'], inplace=True) # not included because of single measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T18:56:18.946484Z",
     "start_time": "2018-07-05T18:56:18.622218Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert easting/northing to lat/long\n",
    "NAD83 = pyproj.Proj(init= 'epsg:2856')\n",
    "WGS84 = pyproj.Proj(init= 'epsg:4326')\n",
    "lon, lat= pyproj.transform(NAD83, WGS84, selected_wells_df['Easting'].values, selected_wells_df['Northing'].values)\n",
    "selected_wells_df['lat'] = lat\n",
    "selected_wells_df['lon'] = lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** customize tile using `attribution` and tileLayer address from [here](http://leaflet-extras.github.io/leaflet-providers/preview/) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T18:48:32.927413Z",
     "start_time": "2018-07-05T18:48:32.925417Z"
    }
   },
   "outputs": [],
   "source": [
    "# Esri.WorldImagery\n",
    "attr = ('Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community')\n",
    "tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stamen.Terrain\n",
    "attr = ('Map tiles by <a href=\"http://stamen.com\">Stamen Design</a>, <a href=\"http://creativecommons.org/licenses/by/3.0\">CC BY 3.0</a> &mdash; Map data &copy; <a href=\"http://www.openstreetmap.org/copyright\">OpenStreetMap</a>')\n",
    "tiles = 'https://stamen-tiles-{s}.a.ssl.fastly.net/terrain/{z}/{x}/{y}{r}.{ext}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T19:12:26.670456Z",
     "start_time": "2018-07-09T19:11:12.478862Z"
    }
   },
   "outputs": [],
   "source": [
    "HFR_map = folium.Map(location=[46.6, -119.5], tiles= tiles,  attr=attr,  zoom_start= 10)\n",
    "\n",
    "df = selected_wells_df.copy()\n",
    "# df = df.head(1)\n",
    "fg = folium.FeatureGroup(name= 'Observed well head')\n",
    "\n",
    "def colorcode(ivalue):\n",
    "    if 'CP' in ivalue :\n",
    "        icolor = 'orange'\n",
    "    else:\n",
    "        icolor = 'blue'\n",
    "    return icolor \n",
    "\n",
    "# resolution, width, height = 75, 7, 3\n",
    "\n",
    "for lat, lon, name in zip(df['lat'], df['lon'], df.index):\n",
    "    \n",
    "    iframe = IFrame('<img src=\"data:image/png;base64,{}\">'.format(base64.b64encode(open(\\\n",
    "                'figures/obs_head/Well {}.png'.format(name), 'rb').read()).decode()), \\\n",
    "                width=800, height=500)\n",
    "    fg.add_child(folium.CircleMarker(location=[lat, lon], \n",
    "#                                      popup=folium.Popup(name),\n",
    "                                     popup = folium.Popup(iframe, max_width=2500),\n",
    "#                                     radius = (value - df['median'].min())/(df['median'].max()-df['median'].min())*10,\n",
    "                                     radius = 5,\n",
    "                                     color = colorcode(name),\n",
    "#                                     fill = False,\n",
    "#                                     fill_color = 'crimson',\n",
    "                                    ))  \n",
    "## add legend to map\n",
    "# url = \"https://github.com/pshuai88/notebook/raw/master/figures/RMSE_legend.png\"\n",
    "# FloatImage(url, bottom = 75, left= 75).add_to(HFR_map)\n",
    "\n",
    "# FloatImage(iframe, bottom = 75, left= 75).add_to(fg)\n",
    "    \n",
    "HFR_map.add_child(fg)\n",
    "\n",
    "## add hanford bc\n",
    "hanford_bc = geopandas.read_file(fname_hanford_shp)\n",
    "hanford_bc_wgs84 = hanford_bc.to_crs({'init': 'epsg:4326'})\n",
    "hanford_bc_json = hanford_bc_wgs84.to_json()\n",
    "# you can use either GeoJson or GeoPandas file\n",
    "folium.GeoJson(hanford_bc_json, name = 'hanford_bc',\n",
    "               style_function=lambda feature: {\n",
    "                'fillColor':'blue',\n",
    "               'color':'white',\n",
    "                   'weight':2,\n",
    "                'fillOpacity':0,\n",
    "               }\n",
    "              ).add_to(HFR_map)\n",
    "\n",
    "## add map layer\n",
    "folium.TileLayer('openstreetmap').add_to(HFR_map)\n",
    "\n",
    "HFR_map.add_child(folium.LayerControl())\n",
    "HFR_map.save('figures/all_obs_wells.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export simulated head using .TEC obsvervation files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import well observation from .tec outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assemble all output data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T22:56:15.657058Z",
     "start_time": "2018-05-24T22:56:15.651878Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tec_files = glob.glob(fname_tec_files)\n",
    "tec_files = natsorted(tec_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T18:04:38.019868Z",
     "start_time": "2018-05-25T18:00:16.977428Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simu_data_df = pd.DataFrame()\n",
    "\n",
    "for ifile in tec_files[:] :   \n",
    "    idf_first = pd.read_table(ifile, sep=',',header=None, nrows=1, engine='python')\n",
    "    iheader = list(np.asarray(idf_first.values).flatten())\n",
    "    idf = pd.read_table(ifile, sep='\\s+',header=None, names=iheader, index_col=0, skiprows=1, engine='python')\n",
    "    \n",
    "    simu_data_df = pd.concat([simu_data_df, idf], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T18:06:26.115470Z",
     "start_time": "2018-05-25T18:06:17.326416Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(fname_simu_data_df_pickle, \"wb\") as f:\n",
    "    pickle.dump((simu_data_df), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grep well data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T23:39:58.842399Z",
     "start_time": "2018-06-08T23:39:58.819543Z"
    }
   },
   "outputs": [],
   "source": [
    "obs_well_names = [iname for iname in well_screen.index if well_screen.loc[iname, 'SCREEN_ELEV_TOP'] >= z_bot and \\\n",
    "                 well_screen.loc[iname, 'SCREEN_ELEV_BOTTOM'] <= z_top and \\\n",
    "                  (well_screen.loc[iname, 'SCREEN_ELEV_TOP'] - well_screen.loc[iname, 'SCREEN_ELEV_BOTTOM']) >= dz[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T21:50:32.681717Z",
     "start_time": "2018-05-25T21:50:32.679834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs_var_names = ['Liquid Pressure', 'Total Tracer [M]', 'qlx', 'qly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create multiindex for dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T23:02:01.173297Z",
     "start_time": "2018-05-25T23:01:54.703245Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "well_array = []\n",
    "var_array = []\n",
    "well_screen_array = []\n",
    "\n",
    "for iwell in obs_well_names:\n",
    "    for iobs in obs_var_names:\n",
    "        iwell_id =iwell + '_'\n",
    "#         iobs = 'qlx'\n",
    "        # search for columns contain both iwell_id and iobs\n",
    "        iwell_col_ind = [icol for icol in simu_data_df.columns if iwell_id in icol and iobs in icol] \n",
    "        # add screen interval sequence to well name \n",
    "        iwell_screen_array = [iwell_id + str(e) for e in list(np.arange(len(iwell_col_ind)) + 1)]\n",
    "        iwell_array = [iwell]*len(iwell_col_ind)\n",
    "        ivar_array = [iobs]*len(iwell_col_ind)\n",
    "        \n",
    "        var_array += ivar_array\n",
    "        well_array += iwell_array \n",
    "        well_screen_array += iwell_screen_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T07:19:05.190891Z",
     "start_time": "2018-05-29T07:19:01.171223Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrays = [np.array(well_array), np.array(var_array), np.array(well_screen_array)]\n",
    "\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('WellName', 'VariableName', 'WellInterval'))\n",
    "\n",
    "well_data_df = pd.DataFrame(index=simu_data_df.index, columns=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take a long time to finish.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T08:44:02.910591Z",
     "start_time": "2018-05-29T07:19:18.224450Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iwell in obs_well_names[:]:\n",
    "    print(iwell)\n",
    "    for iobs in obs_var_names[:]:\n",
    "        iwell_id =iwell + '_'\n",
    "        # search for columns contain both iwell_id and iobs\n",
    "        iwell_col_ind = [icol for icol in simu_data_df.columns if iwell_id in icol and iobs in icol] \n",
    "        iwell_screen_array = [iwell_id + str(e) for e in list(np.arange(len(iwell_col_ind)) + 1)]\n",
    "\n",
    "        for i in np.arange(len(iwell_col_ind))[:]:\n",
    "            well_data_df[iwell, iobs, iwell_screen_array[i]] = simu_data_df[iwell_col_ind[i]].values\n",
    "\n",
    "well_data_df = well_data_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T05:11:08.694778Z",
     "start_time": "2018-05-29T05:11:08.669183Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "well_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate flux averaged tracer conc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T08:58:47.027002Z",
     "start_time": "2018-05-29T08:44:09.849242Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iwell in obs_well_names[:]:\n",
    "    print(iwell)\n",
    "    obs_vec_df = np.sqrt(well_data_df[iwell, 'qlx']**2 + well_data_df[iwell, 'qly']**2)\n",
    "    well_data_df[iwell,'Total Tracer [M]', 'flux_ave_tracer'] = (well_data_df[iwell, 'Total Tracer [M]'] * obs_vec_df).sum(axis = 1) / obs_vec_df.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T16:18:03.827179Z",
     "start_time": "2018-05-29T16:18:00.023160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(fname_well_data_df_pickle, \"wb\") as f:\n",
    "    pickle.dump((well_data_df), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot well simu vs obs head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T23:40:28.686786Z",
     "start_time": "2018-06-08T23:40:21.035472Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading objects    \n",
    "with open(fname_well_data_df_pickle, \"rb\") as f:\n",
    "    well_data_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T23:41:05.618947Z",
     "start_time": "2018-06-08T23:41:05.449833Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_time_6h = []\n",
    "for itime in np.arange(len(well_data_df.index)):\n",
    "    itime_str = list(batch_delta_to_time(date_origin, [float(well_data_df.index[itime])], \"%Y-%m-%d %H:%M:%S\", \"hours\"))\n",
    "    itime_str = ''.join(itime_str)\n",
    "    real_time_6h.append(datetime.datetime.strptime(itime_str, \"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T00:34:52.345433Z",
     "start_time": "2018-06-07T00:06:57.436784Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "RMSE_df = screen_300A_HEIS.copy()\n",
    "RMSE_df['RMSE'] = np.nan\n",
    "\n",
    "for iwell in obs_well_names[:]:\n",
    "#     iwell = '399-1-67'\n",
    "    print(iwell)\n",
    "#     iwell_screen_index = np.asarray(np.where(well_screen.index == iwell)).flatten()\n",
    "    iwell_interval_index = np.where((z >= well_screen.loc[iwell, 'SCREEN_ELEV_BOTTOM']) \\\n",
    "                                    & (z <= well_screen.loc[iwell, 'SCREEN_ELEV_TOP']))\n",
    "    iwell_interval_index = np.asarray(iwell_interval_index).flatten()\n",
    "\n",
    "    z_reshape = z[iwell_interval_index].reshape(1, len(iwell_interval_index))\n",
    "\n",
    "    isimu_head = well_data_df[iwell, 'Liquid Pressure'].copy()\n",
    "    isimu_head = (isimu_head - P_atm) / rho / g_const\n",
    "    # apply broadcasting rule\n",
    "    isimu_head_df = pd.DataFrame(isimu_head.values + z_reshape, columns=isimu_head.columns, index=isimu_head.index)\n",
    "    isimu_head_df = isimu_head_df.sort_index()\n",
    "    \n",
    "    selected_well_simu_head = isimu_head_df.iloc[:, 0].to_frame(name='simu_head') # choose the bottom screen interval as simu head\n",
    "    selected_well_simu_head['DateTime'] = real_time_6h\n",
    "    selected_well_simu_head.set_index('DateTime', inplace=True)\n",
    "    # read obs.head\n",
    "    if iwell in SFA_well['WellName'].unique():\n",
    "        iobs_head_df = SFA_well[ SFA_well.loc[:, 'WellName'] == iwell].copy()\n",
    "\n",
    "\n",
    "    elif iwell in HEIS_auto['WellName'].unique():\n",
    "        iobs_head_df = HEIS_auto[ HEIS_auto.loc[:, 'WellName'] == iwell].copy()\n",
    "\n",
    "    elif iwell in HEIS_manual['WellName'].unique():\n",
    "        iobs_head_df = HEIS_manual[ HEIS_manual.loc[:, 'WellName'] == iwell].copy()\n",
    "\n",
    "    else:\n",
    "        iobs_head_df = pd.DataFrame()\n",
    "        print('No well obs data available for' + iwell)\n",
    "        continue\n",
    "   \n",
    "    #     iobs_head_df = iobs_head_df.sort_index(axis=1)\n",
    "    iobs_head_df['DateTime'] = iobs_head_df['DateTime'].apply(pd.to_datetime)\n",
    "    iobs_head_df = iobs_head_df.drop_duplicates('DateTime', keep='first') \\\n",
    "                                .sort_values(by = 'DateTime').set_index('DateTime', drop=False)\n",
    "    # filter wells outside of dates\n",
    "    iobs_head_df = iobs_head_df[(iobs_head_df['DateTime'] >= datetime.date(2011, 1, 1)) \\\n",
    "                                & (iobs_head_df['DateTime'] <= datetime.date(2016, 1, 1))]\n",
    "    \n",
    "        \n",
    "    \n",
    "    if iobs_head_df['WL'].count() > 1000 :           \n",
    "        # find closest mass1 location\n",
    "        iwell_easting = well_screen.loc[iwell, 'Easting']\n",
    "        iwell_northing = well_screen.loc[iwell, 'Northing']\n",
    "        dist = np.sqrt((mass1_coord['Easting']- iwell_easting)**2 + (mass1_coord['Northing']- iwell_northing)**2)\n",
    "        mass_id = mass1_coord.loc[np.argmin(dist), 'Mass_ID']\n",
    "\n",
    "        datum_files = glob.glob(fname_river_bc_6h + \"Datum*.txt\")\n",
    "        datum_files = natsorted(datum_files) \n",
    "\n",
    "        for ifile in datum_files:\n",
    "            if '_' + str(mass_id) in ifile:\n",
    "                river_stage = pd.read_table(ifile, sep=' ', header=None, names=['time', 'x', 'y', 'wl'])\n",
    "            elif mass_id == 333:\n",
    "                river_stage = pd.read_table(datum_files[-1], sep=' ', header=None, names=['time', 'x', 'y', 'wl'])\n",
    "\n",
    "    #     idatum = [ifile if '_' + str(mass_id) in ifile else datum_files[-1] for ifile in datum_files]\n",
    "    #     river_stage = pd.read_table(idatum, sep=' ', header=None, names=['time', 'x', 'y', 'wl'])\n",
    "\n",
    "        river_stage.time = batch_delta_to_time(date_origin, river_stage.time.astype(np.float64), \"%Y-%m-%d %H:%M:%S\", \"seconds\")\n",
    "        river_stage['time'] = river_stage['time'].apply(pd.to_datetime)    \n",
    "        ##================== apply moving-average ========================##\n",
    "        # find the mode of frequecy (in sec)\n",
    "        res = iobs_head_df['DateTime'].diff().dt.seconds.value_counts().index[0]\n",
    "        # apply moving average to well with sampling freq.< 3600 sec\n",
    "        win_size = int(6*3600/res) # 6-hour moving average       \n",
    "        if res <= 3600 :\n",
    "            datetime_ind = pd.date_range(start='1/1/2011', end='1/1/2016', freq=str(res) + 'S')\n",
    "            df = pd.DataFrame(np.nan, index=datetime_ind, columns=['WL_nan'])\n",
    "            iobs_head_df = pd.concat([df, iobs_head_df], axis=1, join='outer', join_axes=[df.index])\n",
    "\n",
    "            iobs_head_df['mv_ave_6h'] = iobs_head_df['WL'].rolling(win_size).mean()\n",
    "            style = '-k'\n",
    "#         elif res == 3600 :\n",
    "#             datetime_ind = pd.date_range(start='1/1/2011', end='1/1/2016', freq=str(res) + 'S')\n",
    "#             df = pd.DataFrame(np.nan, index=datetime_ind, columns=['WL_nan'])\n",
    "#             iobs_head_df = pd.concat([df, iobs_head_df], axis=1, join='outer', join_axes=[df.index])        \n",
    "#             win_size = int(6*3600/res)\n",
    "#             iobs_head_df['mv_ave_6h'] = iobs_head_df['WL'].rolling(win_size).mean()\n",
    "#             style = '-k'\n",
    "            ##================= get RMSE====================##\n",
    "            iobs_head_df_6h = iobs_head_df.loc[real_time_6h, 'mv_ave_6h']\n",
    "\n",
    "            df = pd.concat([selected_well_simu_head, iobs_head_df_6h], axis=1).\\\n",
    "                    rename(columns = {'mv_ave_6h': 'obs_head'}).dropna(how = 'any')\n",
    "\n",
    "            iRMSE = math.sqrt(mean_squared_error(df.simu_head, df.obs_head))\n",
    "            \n",
    "            RMSE_df.loc[iwell, 'RMSE'] = iRMSE\n",
    "        \n",
    "        \n",
    "        else :\n",
    "            iobs_head_df['mv_ave_6h'] = iobs_head_df['WL']\n",
    "            style = '-ko'\n",
    "            iRMSE = np.nan\n",
    "        \n",
    "        \n",
    "        ##================= plot simu vs obs head========================##\n",
    "        # fig = plt.figure() # open a canvas\n",
    "        # ax = fig.add_subplot(1, 1, 1) # create 1st subplot on a 1x1 grid\n",
    "        fig, ax = plt.subplots(1, 1) # short hand\n",
    "\n",
    "        # plt.plot(iobs_datetime.iloc[:], iobs_head_df['WL'], 'k-')\n",
    "        # plt.plot(iobs_head_df['DateTime'], iobs_head_df['WL'])\n",
    "\n",
    "        river_stage.plot(x= 'time', y= 'wl', legend=False, ax=ax, color = 'gray' , lw = 1, rot = 0, alpha = 0.5)\n",
    "#         ax.plot(real_time_6h, selected_well_simu_head, 'r-', lw= 1)\n",
    "        selected_well_simu_head.plot(y='simu_head', ax=ax, style='-r', lw=1)\n",
    "        iobs_head_df.plot(x= 'DateTime', y= 'mv_ave_6h', legend=False, ax=ax, style=style ,\\\n",
    "                          markerfacecolor = \"None\", ms = 3, lw = 1, rot = 0)\n",
    "\n",
    "        ax.set_title('Well ' + iwell,  fontweight = 'bold', fontsize = 14)\n",
    "        # format the ticks\n",
    "        ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "        ax.xaxis.set_tick_params('labelbottom')\n",
    "        \n",
    "        ax.set_xlim([real_time_6h[0], real_time_6h[-1]])\n",
    "#         ax.set_ylim([104.5, 108.5])\n",
    "        ax.set_ylabel('Water Level (m)')\n",
    "        ax.set_xlabel('')\n",
    "        ax.legend(['river stage', 'simu.head', 'obs.head'], frameon = False)\n",
    "        if iRMSE != np.nan:\n",
    "            ax.text(0.5,0.9,'RMSE = {:.2}'.format(iRMSE), transform = ax.transAxes)\n",
    "#         fig.autofmt_xdate()\n",
    "        fig.tight_layout()\n",
    "        fig.set_size_inches(8, 5)\n",
    "        fname = fig_simu_obs_wl + 'Well ' + iwell + '_6h_ma_rs' \n",
    "        fig.savefig(fname , dpi=300)\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T04:35:21.697073Z",
     "start_time": "2018-06-07T04:35:21.682209Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = fig_simu_obs_wl + 'RMSE.csv'\n",
    "RMSE_df.to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot well RMSE (obs.head, simu.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T04:35:08.295339Z",
     "start_time": "2018-06-07T04:35:08.282427Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert easting/northing to lat/long\n",
    "NAD83 = pyproj.Proj(init= 'epsg:2856')\n",
    "WGS84 = pyproj.Proj(init= 'epsg:4326')\n",
    "lon, lat= pyproj.transform(NAD83, WGS84, RMSE_df['Easting'].values, RMSE_df['Northing'].values)\n",
    "RMSE_df['lat'] = lat\n",
    "RMSE_df['lon'] = lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T04:59:40.889001Z",
     "start_time": "2018-06-07T04:59:40.880683Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "river_geometry = pd.read_csv(fname_river_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T04:22:47.892008Z",
     "start_time": "2018-06-08T04:22:47.867089Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = fig_simu_obs_wl + 'RMSE.csv'\n",
    "RMSE_df = pd.read_csv(fname)\n",
    "RMSE_df_sub = RMSE_df[RMSE_df.RMSE < 10].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T05:47:33.473224Z",
     "start_time": "2018-06-07T05:47:32.846139Z"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "def colorcode(value):\n",
    "    color = []\n",
    "    for ivalue in value:\n",
    "        if ivalue <= 0.5 :\n",
    "            icolor = 'green'\n",
    "        elif ivalue <= 1 :\n",
    "            icolor = 'orange'\n",
    "        else:\n",
    "            icolor = 'red'\n",
    "        color.append(icolor)\n",
    "    return color   \n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "\n",
    "river_geometry.plot(x = 'x', y= 'y', ax=ax1, style='-k', lw=1, legend= False)\n",
    "\n",
    "plt.scatter(RMSE_df_sub['Easting'].values, RMSE_df_sub['Northing'].values, \\\n",
    "            color= colorcode(RMSE_df_sub.RMSE), marker= 'o', edgecolors = 'face',\\\n",
    "            s = RMSE_df_sub.RMSE*5, alpha = 0.5)\n",
    "\n",
    "# add label for points\n",
    "for i, txt in enumerate(RMSE_df_sub.index):\n",
    "    ax1.annotate(txt, (RMSE_df_sub['Easting'].values[i], RMSE_df_sub['Northing'].values[i]))\n",
    "\n",
    "ax1.set_xlim([550000, 600000])\n",
    "ax1.set_ylabel('Northing')\n",
    "ax1.set_xlabel('Easting')\n",
    "ax1.set_title('RMSE b/w obs.head and simu.head', fontweight = 'bold', fontsize = 14)\n",
    "ax1.set_aspect(\"equal\", \"datalim\")\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='0-0.5 ',\n",
    "                          markerfacecolor='g', markersize=8),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='0.5-1 ',\n",
    "                          markerfacecolor='orange', markersize=8),\n",
    "                    Line2D([0], [0], marker='o', color='w', label='>1 ',\n",
    "                          markerfacecolor='r', markersize=8),\n",
    "                    ]\n",
    "ax1.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "# ax1.legend(handles=legend_elements, loc='best')\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T05:27:52.505525Z",
     "start_time": "2018-06-07T05:27:52.259764Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = fig_simu_obs_wl + 'RMSE.png'\n",
    "fig.savefig(fname, dpi=300)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interactive map with folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T05:51:27.556859Z",
     "start_time": "2018-06-10T05:51:27.549759Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = fig_simu_obs_wl + 'RMSE.csv'\n",
    "RMSE_df = pd.read_csv(fname)\n",
    "RMSE_df_sub = RMSE_df[RMSE_df.RMSE < 10].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T05:51:52.398085Z",
     "start_time": "2018-06-10T05:51:40.033043Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HFR_map = folium.Map(location=[46.6, -119.5], tiles= 'Stamen Terrain', zoom_start= 10)\n",
    "\n",
    "df = RMSE_df_sub.copy()\n",
    "# df = df.head(1)\n",
    "fg = folium.FeatureGroup(name= 'RMSE b/w simu and obs WL')\n",
    "\n",
    "def colorcode(ivalue):\n",
    "    if ivalue <= 0.5 :\n",
    "        icolor = 'green'\n",
    "    elif ivalue <= 1 :\n",
    "        icolor = 'orange'\n",
    "    else:\n",
    "        icolor = 'red'\n",
    "    return icolor \n",
    "\n",
    "resolution, width, height = 75, 7, 3\n",
    "\n",
    "for lat, lon, name, value in zip(df['lat'], df['lon'], df['WellName'], df['RMSE']):\n",
    "    \n",
    "    iframe = IFrame('<img src=\"data:image/png;base64,{}\">'.format(base64.b64encode(open(\\\n",
    "                'figures/wl/Well {}_6h_ma_rs.png'.format(name), 'rb').read()).decode()), \\\n",
    "                width=1200, height=750)\n",
    "    fg.add_child(folium.CircleMarker(location=[lat, lon], \n",
    "#                                      popup=folium.Popup(name),\n",
    "                                     popup = folium.Popup(iframe, max_width=2500),\n",
    "#                                     radius = (value - df['median'].min())/(df['median'].max()-df['median'].min())*10,\n",
    "                                     radius = 5,\n",
    "                                     color = colorcode(value),\n",
    "#                                     fill = False,\n",
    "#                                     fill_color = 'crimson',\n",
    "                                    ))  \n",
    "## add legend to map\n",
    "url = \"https://github.com/pshuai88/notebook/raw/master/figures/RMSE_legend.png\"\n",
    "FloatImage(url, bottom = 75, left= 75).add_to(HFR_map)\n",
    "\n",
    "# FloatImage(iframe, bottom = 75, left= 75).add_to(fg)\n",
    "    \n",
    "HFR_map.add_child(fg)\n",
    "HFR_map.add_child(folium.LayerControl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T05:52:38.222292Z",
     "start_time": "2018-06-10T05:52:32.089077Z"
    }
   },
   "outputs": [],
   "source": [
    "HFR_map.save('figures/RMSE_popup.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot well tracer vs SpC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T23:30:41.107349Z",
     "start_time": "2018-06-08T23:30:40.542646Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "selected_chemical = 'Specific Conductance'\n",
    "iobs_chemical = GW_chem[GW_chem.loc[:,'Chemical'] == selected_chemical].copy()\n",
    "iobs_chemical.rename(columns={'Concentration': 'Spc'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**export tracer to .csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_list = ['199-H1-7', '199-H3-25', '199-H3-5', '199-H3-7']\n",
    "for iwell in well_list[0:]:\n",
    "    print(iwell)\n",
    "    itracer_df = well_data_df[iwell, 'Total Tracer [M]', 'flux_ave_tracer'].copy()\n",
    "    idf = pd.DataFrame({'DateTime':real_time_6h, 'tracer_conc':itracer_df.values})\n",
    "    fname = out_dir + iwell + '_tracer.csv'\n",
    "    idf.to_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T05:12:05.576437Z",
     "start_time": "2018-06-10T05:02:45.124870Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "spc_map_well = []\n",
    "for iwell in obs_well_names[:]:\n",
    "#     iwell = '399-3-9'\n",
    "#     iwell = '399-2-33'\n",
    "    print(iwell)\n",
    "    iobs_data_df = pd.DataFrame()\n",
    "    \n",
    "    itracer_df = well_data_df[iwell, 'Total Tracer [M]', 'flux_ave_tracer'].copy()\n",
    "    \n",
    "    # read obs.head\n",
    "    if iwell in SFA_well['WellName'].unique():\n",
    "        iobs_data_df = SFA_well[SFA_well.loc[:, 'WellName'] == iwell].copy()\n",
    "        iobs_data_df['Spc'] = iobs_data_df['Spc']*1000 # convert ms/cm to us/cm\n",
    "\n",
    "    elif iwell in iobs_chemical['WellName'].unique():\n",
    "        iobs_data_df = iobs_chemical[iobs_chemical.loc[:, 'WellName'] == iwell].copy() \n",
    "\n",
    "    else:\n",
    "        print('No spc data for well ' + iwell)\n",
    "        continue\n",
    "        \n",
    "    iobs_data_df = iobs_data_df.drop_duplicates('DateTime', keep='first') \\\n",
    "                                .sort_values(by = 'DateTime').set_index('DateTime', drop=False).sort_index()\n",
    "    # filter wells outside of dates\n",
    "    iobs_data_df = iobs_data_df[(iobs_data_df['DateTime'] >= datetime.date(2011, 1, 1)) \\\n",
    "                                & (iobs_data_df['DateTime'] <= datetime.date(2016, 1, 1))]   \n",
    "    \n",
    "    if iobs_data_df['Spc'].count() > 10 and iobs_data_df['Spc'].isnull().all() == False and itracer_df.max()>= 0.1:   \n",
    "        spc_map_well.append(iwell)\n",
    "        # find closest mass1 location\n",
    "        iwell_easting = well_screen.loc[iwell, 'Easting']\n",
    "        iwell_northing = well_screen.loc[iwell, 'Northing']\n",
    "        dist = np.sqrt((mass1_coord['Easting']- iwell_easting)**2 + (mass1_coord['Northing']- iwell_northing)**2)\n",
    "        mass_id = mass1_coord.loc[np.argmin(dist), 'Mass_ID']\n",
    "\n",
    "        datum_files = glob.glob(fname_river_bc_6h + \"Datum*.txt\")\n",
    "        datum_files = natsorted(datum_files) \n",
    "\n",
    "        for ifile in datum_files:\n",
    "            if '_' + str(mass_id) in ifile:\n",
    "                river_stage = pd.read_table(ifile, sep=' ', header=None, names=['time', 'x', 'y', 'wl'])\n",
    "            elif mass_id == 333:\n",
    "                river_stage = pd.read_table(datum_files[-1], sep=' ', header=None, names=['time', 'x', 'y', 'wl'])\n",
    "\n",
    "        river_stage.time = batch_delta_to_time(date_origin, river_stage.time.astype(np.float64), \"%Y-%m-%d %H:%M:%S\", \"seconds\")\n",
    "        river_stage['time'] = river_stage['time'].apply(pd.to_datetime)  \n",
    "        river_stage = river_stage[(river_stage['time'] >= datetime.date(2011, 1, 1)) \\\n",
    "                            & (river_stage['time'] <= datetime.date(2016, 1, 1))]   \n",
    "        \n",
    "        # find the mode of frequecy (in sec)\n",
    "        res = iobs_data_df['DateTime'].diff().dt.seconds.value_counts().index[0]\n",
    "        val = iobs_data_df['DateTime'].diff().dt.seconds.value_counts().values[0]\n",
    "        if res <= 86400 and val >=100 :    \n",
    "            style = '-k'\n",
    "        else:\n",
    "            style = '-ko'\n",
    "#     iobs_data_df['Spc'] = (iobs_data_df['Spc'] - spc_u_data['Spc'].min()) / (spc_u_data['Spc'].max() - spc_u_data['Spc'].min())\n",
    "#     iobs_data_df['Spc'] = (iobs_data_df['Spc'] - well_data['Spc'].min()) / (well_data['Spc'].max() - well_data['Spc'].min())\n",
    "\n",
    "\n",
    "        ## ============= plot tracer vs SpC===================##\n",
    "#         fig, ax1 = plt.subplots(1, 1)  # short hand\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(3, 1, 1)\n",
    "        \n",
    "#         river_stage.plot(x= 'time', y= 'wl', legend=False, ax=ax1, color = 'gray' , lw = 1, rot = 0, alpha = 0.5)\n",
    "        ax1.plot(river_stage.time, river_stage.wl, color = 'gray' , lw = 1, alpha = 0.5)        \n",
    "        ax1.set_xlim([real_time_6h[0], real_time_6h[-1]])\n",
    "        ax1.set_ylabel('River Stage (m)', color='k')\n",
    "#         ax1.legend()\n",
    "        \n",
    "        ax2 = fig.add_subplot(3, 1, (2,3), sharex = ax1)\n",
    "#         plt1 = iobs_data_df.plot(x='DateTime', y='Spc', style = style, lw = 1, ms = 3, \\\n",
    "#                                  mfc='None' , markeredgewidth= 0.5, color='k', legend=False, ax=ax2, rot=0)\n",
    "        ax2.plot(iobs_data_df.DateTime, iobs_data_df.Spc, style, lw = 1, ms = 3, \\\n",
    "                                 mfc='None' , markeredgewidth= 0.5, color='k')\n",
    "        ax2.set_xlim([real_time_6h[0], real_time_6h[-1]])\n",
    "\n",
    "        ax2.set_ylabel(r'SpC ($\\mu$s/cm)', color='k')\n",
    "        ax2.set_xlabel('')\n",
    "        ax2.tick_params('y', colors='k')\n",
    "#         ax2.legend(['SpC'], frameon=False,\n",
    "#                    loc='lower left', bbox_to_anchor=(0, 0.95))\n",
    "        \n",
    "\n",
    "        # create another y-scale using the same x axis\n",
    "        ax3 = ax2.twinx()\n",
    "        plt2 = ax3.plot(real_time_6h, itracer_df.values, 'r-', lw = 1)\n",
    "\n",
    "        \n",
    "        ax3.set_ylim([0, 1])\n",
    "#         ax2.set_xlim([real_time_6h[0], real_time_6h[-1]])\n",
    "        ax3.set_ylabel('tracer (-)', color='r')\n",
    "        ax3.tick_params('y', colors='r')\n",
    "#         ax3.legend(['tracer'], frameon=False,\n",
    "#                    loc='lower left', bbox_to_anchor=(0, 0.90))\n",
    "        \n",
    "        plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "        plt.minorticks_off()\n",
    "        plt.suptitle('Well ' + iwell, fontweight = 'bold', fontsize = 14)\n",
    "        fig.tight_layout()\n",
    "        fname = fig_tracer_spc + 'Well ' + iwell + '_spc_10'\n",
    "        fig.set_size_inches(8, 5)\n",
    "        fig.savefig(fname, dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show wells using folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T05:48:59.682682Z",
     "start_time": "2018-06-10T05:48:59.672523Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(fname_GW_spc_summary, index_col='WellName')\n",
    "\n",
    "df = df.loc[spc_map_well]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T05:49:08.571330Z",
     "start_time": "2018-06-10T05:49:01.265689Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HFR_map = folium.Map(location=[46.6, -119.5], tiles= 'Stamen Terrain', zoom_start= 10)\n",
    "\n",
    "# df = df.head(1)\n",
    "fg = folium.FeatureGroup(name= 'Tracer vs SpC')\n",
    "\n",
    "def colorcode(ivalue):\n",
    "    if ivalue <= 100 :\n",
    "        icolor = 'green'\n",
    "    elif ivalue <= 300 :\n",
    "        icolor = 'orange'\n",
    "    elif ivalue <= 500 :\n",
    "        icolor = 'purple'\n",
    "    else:\n",
    "        icolor = 'red'\n",
    "    return icolor   \n",
    "\n",
    "resolution, width, height = 75, 7, 3\n",
    "## add popup image \n",
    "# png = 'figures/{}_map_legend.png'.format('nitrate')\n",
    "# encoded = base64.b64encode(open(png, 'rb').read()).decode()\n",
    "# html = '<img src=\"data:image/png;base64,{}\">'.format\n",
    "# iframe = IFrame(html(encoded), width=(width*resolution)+20, height=(height*resolution)+20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for lat, lon, name, value in zip(df['latitude'], df['longitude'], df.index, df['median']):\n",
    "    \n",
    "    iframe = IFrame('<img src=\"data:image/png;base64,{}\">'.format(base64.b64encode(open(\\\n",
    "                'figures/spc/Well {}_spc_10.png'.format(name), 'rb').read()).decode()), \\\n",
    "                width=1200, height=750)\n",
    "    fg.add_child(folium.CircleMarker(location=[lat, lon], \n",
    "#                                      popup=folium.Popup(name),\n",
    "                                     popup = folium.Popup(iframe, max_width=2500),\n",
    "#                                     radius = (value - df['median'].min())/(df['median'].max()-df['median'].min())*10,\n",
    "                                     radius = 5,\n",
    "                                     color = colorcode(value),\n",
    "#                                     fill = False,\n",
    "#                                     fill_color = 'crimson',\n",
    "                                    ))  \n",
    "## add legend to map\n",
    "HFR_map.save('figures/RMSE_popup.html')\n",
    "url = \"https://github.com/pshuai88/notebook/raw/master/figures/spc_legend.png\"\n",
    "FloatImage(url, bottom = 75, left= 75).add_to(HFR_map)\n",
    "\n",
    "# FloatImage(iframe, bottom = 75, left= 75).add_to(fg)\n",
    "    \n",
    "HFR_map.add_child(fg)\n",
    "HFR_map.add_child(folium.LayerControl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T05:51:14.383302Z",
     "start_time": "2018-06-10T05:51:10.759602Z"
    }
   },
   "outputs": [],
   "source": [
    "HFR_map.save('figures/spc_popup.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show wells using mplleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T21:19:27.235595Z",
     "start_time": "2018-05-31T21:19:27.082103Z"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "ichemical = pd.read_csv(fname_GW_NO3_summary)\n",
    "medianConc = ichemical['median'].values /1000  # convert ug/L to mg/L\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(ichemical.longitude, ichemical.latitude)]\n",
    "crs = {'init': 'epsg:4326'}\n",
    "geo_df = GeoDataFrame(ichemical, crs = crs, geometry = geometry)\n",
    "\n",
    "def colorcode(value):\n",
    "    color = []\n",
    "    for ivalue in value:\n",
    "        if ivalue <= 10 :\n",
    "            icolor = 'green'\n",
    "        elif ivalue <= 30 :\n",
    "            icolor = 'orange'\n",
    "        elif ivalue <= 50 :\n",
    "            icolor = 'purple'\n",
    "        else:\n",
    "            icolor = 'red'\n",
    "        color.append(icolor)\n",
    "    return color \n",
    "\n",
    "ax = geo_df.plot(column = 'median', color = colorcode(medianConc))\n",
    "\n",
    "# ax.legend(handles=legend_elements, loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T21:25:32.524616Z",
     "start_time": "2018-05-31T21:25:31.901048Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tile option: cartodb_positron, esri_worldtopo, \n",
    "tiles = ['cartodb_positron', 'esri_aerial', 'esri_worldtopo', 'mapbox bright']\n",
    "mplleaflet.show(fig=ax.figure, crs=geo_df.crs, tiles = tiles[1], path= 'nitrate_map_aerial.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show well location using Leaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T16:34:07.479898Z",
     "start_time": "2018-05-22T16:34:07.451246Z"
    }
   },
   "source": [
    "create GEOjson file to load into leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T16:31:31.151594Z",
     "start_time": "2018-05-22T16:31:31.019275Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nitrate_coord_agg = pd.read_csv(fname_GW_NO3_coord)\n",
    "\n",
    "# create GEOjson file to load into leaflet\n",
    "json_result_string = nitrate_coord_agg.to_json(\n",
    "    orient='records', \n",
    "    double_precision=12,\n",
    "    date_format='iso'\n",
    ")\n",
    "json_result = json.loads(json_result_string)\n",
    "\n",
    "geojson = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': []\n",
    "}\n",
    "for record in json_result:\n",
    "    geojson['features'].append({\n",
    "        'type': 'Feature',\n",
    "        'geometry': {\n",
    "            'type': 'Point',\n",
    "            'coordinates': [record['longitude'], record['latitude']],  # GeoJSON need coord in long and lat order\n",
    "        },\n",
    "        'properties': record,\n",
    "    })\n",
    "\n",
    "# save json file\n",
    "with open(fname_GW_NO3_geojson, 'w') as f:\n",
    "    f.write(json.dumps(geojson, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overlay wells on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T17:01:08.938561Z",
     "start_time": "2018-05-31T17:01:08.925687Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Map(center=(46.6, -119.5), zoom=10, layout = dict(width = '600px', height = '600px'),  basemap=basemaps.Esri.WorldImagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T17:43:40.750706Z",
     "start_time": "2018-05-22T17:43:40.734967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = ipyw.Label(layout=ipyw.Layout(width='100%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T17:02:36.188944Z",
     "start_time": "2018-05-31T17:02:35.956289Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(fname_GW_NO3_geojson, 'r') as f:\n",
    "    data = json.load(f)\n",
    "# for feature in data['features']:\n",
    "#     feature['properties']['style'] = {\n",
    "#         'color': 'grey',\n",
    "#         'weight': 1,\n",
    "#         'fillColor': 'grey',\n",
    "#         'fillOpacity': 0.5\n",
    "#     }\n",
    "layer = GeoJSON(data=data, name='Nitrate')\n",
    "\n",
    "def hover_handler(event=None, id=None, properties=None):\n",
    "    label.value = properties['WellName']\n",
    "\n",
    "layer.on_hover(hover_handler)\n",
    "\n",
    "m.add_layer(layer)\n",
    "# Adding the control# Addin \n",
    "m.add_control(LayersControl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T17:04:09.120209Z",
     "start_time": "2018-05-31T17:04:09.118345Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate simulated head using H5 output\n",
    "We can calculate total head by $$H = h + z, (h = (P-P_{atm})/\\gamma/g)$$  \n",
    "which $h$ has shape of **(100, 300, 300)**, and $z$ has shape of **(100,)**. To use broadcasting rule, the dimension of two arrays must match or either one has $dim = 1$. In this case, $z$ is reshaped to **(100, 1, 1)**. that is $$ H(100, 300, 300) = h(100,300,300) + z(100, 1, 1) $$\n",
    "\n",
    "\n",
    "note: when importing hdf5 dataset of dimension **(nx, ny, nz)**, the shape of numpy array will be **(nx, ny, nz)**. The correct logical shape in numpy would need to change to **(nz, ny, nx)** by using `np.swapaxes(0, 2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using interpolation to get well simu data at given location\n",
    "notes about using scipy.interpolate:\n",
    "* **`interpolate.Rbf`** performs best for irregular dataset compared to `interpolate.interp2d` and `interpolate.griddata` and can do both interpolation and extrapolation, however, it is **extremely slow** for large dataset. Note: __`.Rbf` method could not have duplicate in points, otherwise it will return sigular matrix__ (see this [post](https://stackoverflow.com/questions/37872171/how-can-i-perform-two-dimensional-interpolation-using-scipy))\n",
    "* **`interpolate.RectBivariateSpline`** is fast for structured grid, however, it will return NaN if there is missing data in the inputs. A work around is to replace those missing data with 0 or -9999. After interpolation, set those missing data to NaN again. (see this [post](https://stackoverflow.com/questions/15485343/bivariate-structured-interpolation-of-large-array-with-nan-values-or-mask)) (_note: this method can create some erratic numbers (negative concentration)_)\n",
    "* **`interpolate.griddata`** interpolate scatter points to a regular grid. It does not perform extrapolation. Need to test its performance against large dataset.\n",
    "\n",
    "**note:** this method won't work where there are inactive cells (NA) surrounding wells. In this case, river shore wells yield underestimated water level using interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize arrays...\n",
    "Be careful using `np.empty()`, it will generate random number in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-18T23:35:34.362804Z",
     "start_time": "2018-05-18T23:35:34.358512Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "well_simu_head = np.zeros((len(time_index), nz, len(well_screen.index))) # initialize array to store simu.head at obs.wells\n",
    "well_xflux = np.zeros((len(time_index), nz, len(well_screen.index))) # initialize array to store abs.flux at obs.wells\n",
    "well_yflux = np.zeros((len(time_index), nz, len(well_screen.index))) # initialize array to store abs.flux at obs.wells\n",
    "well_ave_tracer = np.zeros((len(time_index), len(well_screen.index))) # store flux-average tracer conc.\n",
    "well_tracer = np.zeros((len(time_index), nz, len(well_screen.index))) # initialize array to store tracer conc. at obs.wells\n",
    "\n",
    "# create index for well screen intervals range within model domain\n",
    "interval_index = np.where((z >= np.min(well_screen['SCREEN_ELEV_BOTTOM'])) \\\n",
    "                          & (z <= np.max(well_screen['SCREEN_ELEV_TOP'])))\n",
    "interval_index = np.asarray(interval_index).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T01:04:34.449611Z",
     "start_time": "2018-05-19T00:07:21.946088Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop over time step\n",
    "for itime in np.arange(len(time_index))[:]:\n",
    "#         ipdb.set_trace()\n",
    "    print(time_index[itime])\n",
    "    real_itime = batch_delta_to_time(date_origin, [float(time_index[itime][7:18])], \"%Y-%m-%d %H:%M:%S\", \"hours\")\n",
    "    real_itime = str(real_itime)\n",
    "    print(real_itime, type(real_itime))\n",
    "    # read pressure\n",
    "    temp_pressure = np.asarray(list(input_h5[time_index[itime]][\"Liquid_Pressure [Pa]\"])).swapaxes(0,2)\n",
    "    temp_pressure[temp_pressure == 0] = np.nan # replace 0 (inactive cell pressure) with nan to avoid calculations\n",
    "\n",
    "    # convert liquid_pressure to pressure head\n",
    "    temp_head = (temp_pressure - P_atm) / rho / g_const\n",
    "    # reshape z to use broadcasting rule\n",
    "    z_reshape = z.reshape(nz, 1, 1)\n",
    "    # total head  = presure head + elevation head\n",
    "    temp_total_head = temp_head + z_reshape\n",
    "\n",
    "    # create a copy of total_head and replace nan with 0\n",
    "    total_head_copy = temp_total_head.copy()\n",
    "    total_head_copy = np.nan_to_num(total_head_copy) # replace nan with 0 for interpolation\n",
    "    \n",
    "    # calculate ave. tracer conc. at wells\n",
    "    xflux = np.asarray(list(input_h5[time_index[itime]]['Liquid X-Flux Velocities'])).swapaxes(0,2) \n",
    "    yflux = np.asarray(list(input_h5[time_index[itime]]['Liquid Y-Flux Velocities'])).swapaxes(0,2)\n",
    "\n",
    "    \n",
    "    temp_tracer = np.asarray(list(input_h5[time_index[itime]]['Total_Tracer [M]'])).swapaxes(0,2)\n",
    "#     temp_tracer[temp_tracer == 0] = np.nan\n",
    "    # interpolate head at each iz layer\n",
    "    for iz in interval_index:\n",
    "        f_head = interpolate.RectBivariateSpline(y, x, total_head_copy[iz, :,:])\n",
    "        f_xflux = interpolate.RectBivariateSpline(y, x_grids[1:-1], xflux[iz, :,:]) #x-flux shape is different from y-flux shape\n",
    "        f_yflux = interpolate.RectBivariateSpline(y_grids[1:-1], x, yflux[iz, :,:])        \n",
    "        f_tracer = interpolate.RectBivariateSpline(y, x, temp_tracer[iz, :,:])\n",
    "#         f_tracer = interpolate.SmoothBivariateSpline(yy.flatten(), xx.flatten(), temp_tracer[iz, :,:].flatten())        \n",
    "        # evaluate at well points\n",
    "        well_simu_head[itime, iz, :] = f_head.ev(well_screen['Northing'], well_screen['Easting']) \n",
    "\n",
    "        well_xflux[itime, iz, :] = f_xflux.ev(well_screen['Northing'], well_screen['Easting'])\n",
    "        well_yflux[itime, iz, :] = f_yflux.ev(well_screen['Northing'], well_screen['Easting'])\n",
    "        \n",
    "        well_tracer[itime, iz, :] = f_tracer.ev(well_screen['Northing'], well_screen['Easting']) # has negative value?\n",
    "    \n",
    "    well_tracer[well_tracer < 0] = np.nan     \n",
    "    # calculate flux averageing tracer at each well\n",
    "    for iwell in well_screen.index[:]:\n",
    "    #     iwell = '399-1-10A'\n",
    "#         print(iwell)\n",
    "        iwell_abs_flux = []\n",
    "        iwell_screen_index = np.asarray(np.where(well_screen.index == iwell)).flatten()\n",
    "        iwell_interval_index = np.where((z > well_screen.loc[iwell, 'SCREEN_ELEV_BOTTOM']) \\\n",
    "                                        & (z < well_screen.loc[iwell, 'SCREEN_ELEV_TOP']))\n",
    "        iwell_interval_index = np.asarray(iwell_interval_index).flatten()\n",
    "        \n",
    "        iwell_abs_flux = np.sqrt(well_xflux[itime, iwell_interval_index, iwell_screen_index]**2 + \\\n",
    "                                well_yflux[itime, iwell_interval_index, iwell_screen_index]**2)\n",
    "        iwell_abs_flux = np.asarray(iwell_abs_flux).flatten()\n",
    "        well_ave_tracer[itime, iwell_screen_index] = np.sum(iwell_abs_flux*well_tracer[itime, iwell_interval_index, \\\n",
    "                                                                                       iwell_screen_index])/np.sum(iwell_abs_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dump files using `pickle.dump` and load files using `pickle.load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T05:33:58.745198Z",
     "start_time": "2018-05-19T05:33:13.200713Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving objects\n",
    "with open(fname_well_simu_data_pk, \"wb\") as f:\n",
    "    pickle.dump((well_simu_head, well_xflux, well_yflux, well_tracer, well_ave_tracer), f)\n",
    "# # loading objects    \n",
    "# with open(fname_well_simu_data_pk, \"rb\") as f:\n",
    "#     well_simu_head, well_xflux, well_yflux, well_tracer, well_ave_tracer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot well simu vs obs head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T05:26:34.512921Z",
     "start_time": "2018-05-20T04:57:30.772851Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "for iwell in well_screen.index[17:]:\n",
    "#     iwell = '399-2-10'\n",
    "    print(iwell)\n",
    "    iwell_screen_index = np.asarray(np.where(well_screen.index == iwell)).flatten()\n",
    "    iwell_interval_index = np.where((z >= well_screen.loc[iwell, 'SCREEN_ELEV_BOTTOM']) \\\n",
    "                                    & (z <= well_screen.loc[iwell, 'SCREEN_ELEV_TOP']) \\\n",
    "                                   )\n",
    "    iwell_interval_index = np.asarray(iwell_interval_index).flatten()\n",
    "    # well head is taken at the lowest screen interval--iwell_interval_index[0]\n",
    "    \n",
    "    if iwell_interval_index.size > 0:\n",
    "        isimu_head = well_simu_head[:, iwell_interval_index[0], iwell_screen_index]\n",
    "        isimu_head = isimu_head.reshape(isimu_head.shape[0])\n",
    "    \n",
    "    # read obs.head\n",
    "    if iwell in SFA_well['WellName'].unique():\n",
    "        iobs_head_df = SFA_well[ SFA_well.loc[:, 'WellName'] == iwell].copy()\n",
    "        iobs_head_df['DateTime'] = iobs_head_df['DateTime'].apply(pd.to_datetime)\n",
    "    elif iwell in HEIS_auto['WellName'].unique():\n",
    "        iobs_head_df = HEIS_auto[ HEIS_auto.loc[:, 'WellName'] == iwell].copy()\n",
    "        iobs_head_df['DateTime'] = iobs_head_df['DateTime'].apply(pd.to_datetime)\n",
    "    elif iwell in HEIS_manual['WellName'].unique():\n",
    "        iobs_head_df = HEIS_manual[ HEIS_manual.loc[:, 'WellName'] == iwell].copy()\n",
    "        iobs_head_df['DateTime'] = iobs_head_df['DateTime'].apply(pd.to_datetime)\n",
    "    else:\n",
    "        iobs_head_df = pd.DataFrame()\n",
    "        print('No well obs data available for' + iwell)\n",
    "   \n",
    "    if iobs_head_df.size > 0:\n",
    "        ##================= plot simu vs obs head========================##\n",
    "        # fig = plt.figure() # open a canvas\n",
    "        # ax = fig.add_subplot(1, 1, 1) # create 1st subplot on a 1x1 grid\n",
    "        fig, ax = plt.subplots(1, 1) # short hand\n",
    "\n",
    "        # plt.plot(iobs_datetime.iloc[:], iobs_head_df['WL'], 'k-')\n",
    "        # plt.plot(iobs_head_df['DateTime'], iobs_head_df['WL'])\n",
    "\n",
    "\n",
    "        iobs_head_df.plot(x= 'DateTime', y= 'WL', color='k', legend=False, ax=ax, \n",
    "                         figsize = (8, 5), title = 'Well ' + iwell,\n",
    "                         rot = 0)\n",
    "        plt.plot(real_time_index, isimu_head, 'r-')\n",
    "\n",
    "        ax.set_xlim([real_time_index[0], real_time_index[-1]])\n",
    "#         ax.set_ylim([104.5, 108.5])\n",
    "        ax.set_ylabel('Water Level (m)')\n",
    "        ax.set_xlabel('')\n",
    "        ax.legend(['obs.head', 'simu.head'], frameon = False)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fname = fig_simu_obs_wl + 'Well ' + iwell \n",
    "        fig.savefig(fname , dpi=300)\n",
    "        plt.close(fig)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot well tracer vs SpC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T07:13:27.042970Z",
     "start_time": "2018-05-20T06:54:26.077281Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "selected_chemical = 'Specific Conductance'\n",
    "iobs_chemical = GW_chem[GW_chem.loc[:,'Chemical'] == selected_chemical].copy()\n",
    "iobs_chemical.rename(columns={'Chemical': 'Spc'}, inplace = True)\n",
    "\n",
    "for iwell in well_screen.index[:]:\n",
    "#     iwell = '399-1-10A'\n",
    "    print(iwell)\n",
    "    iobs_data_df = pd.DataFrame()\n",
    "    iwell_screen_index = np.asarray(np.where(well_screen.index == iwell)).flatten()\n",
    "    \n",
    "    itracer = well_ave_tracer[:, iwell_screen_index]\n",
    "    \n",
    "    \n",
    "    # read obs.head\n",
    "#     iobs_data_df = spc_u_data[ spc_u_data.loc[:, 'WellName'] == iwell].copy()\n",
    "    if iwell in SFA_well['WellName'].unique():\n",
    "        iobs_data_df = SFA_well[SFA_well.loc[:, 'WellName'] == iwell].copy()\n",
    "        iobs_data_df['Spc'] = iobs_data_df['Spc']*1000\n",
    "        iobs_data_df['DateTime'] = iobs_data_df['DateTime'].apply(pd.to_datetime)\n",
    "    elif iwell in iobs_chemical['WellName'].unique():\n",
    "        iobs_data_df = iobs_chemical[iobs_chemical.loc[:, 'WellName'] == iwell].copy()        \n",
    "    else:\n",
    "        print('No spc data for well ' + iwell)\n",
    "\n",
    "#     iobs_data_df['Spc'] = (iobs_data_df['Spc'] - spc_u_data['Spc'].min()) / (spc_u_data['Spc'].max() - spc_u_data['Spc'].min())\n",
    "#     iobs_data_df['Spc'] = (iobs_data_df['Spc'] - SFA_well['Spc'].min()) / (SFA_well['Spc'].max() - SFA_well['Spc'].min())\n",
    "    if iobs_data_df.size > 0 and iobs_data_df['Spc'].isnull().all() == False:\n",
    "\n",
    "        ## ============= plot tracer vs SpC===================##\n",
    "        fig, ax1 = plt.subplots(1, 1)  # short hand\n",
    "\n",
    "        plt1 = iobs_data_df.plot(x='DateTime', y='Spc', linestyle='-',marker='o', \\\n",
    "                                 mfc='none' , markeredgewidth= 0.5, color='k', legend=False, ax=ax1, rot=0)\n",
    "\n",
    "    #         ax1.title('Well ' + iwell)\n",
    "        ax1.set_xlim([real_time_index[0], real_time_index[-1]])\n",
    "    #         ax1.set_ylim([0, 1])\n",
    "    #         ax.set_ylim([104.5, 108.5])\n",
    "        ax1.set_ylabel(r'SpC ($\\mu$s/cm)', color='k')\n",
    "        ax1.set_xlabel('')\n",
    "        ax1.tick_params('y', colors='k')\n",
    "        ax1.legend(['SpC'], frameon=False,\n",
    "                   loc='lower left', bbox_to_anchor=(0, 1))\n",
    "        plt.suptitle('Well' + iwell)\n",
    "\n",
    "        # create another y-scale using the same x axis\n",
    "        ax2 = ax1.twinx()\n",
    "        plt2 = ax2.plot(real_time_index, itracer, 'r-')\n",
    "        ax2.set_ylim([0, 1])\n",
    "        ax2.set_ylabel('tracer (-)', color='r')\n",
    "        ax2.tick_params('y', colors='r')\n",
    "        ax2.legend(['tracer'], frameon=False,\n",
    "                   loc='lower right', bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fname = fig_tracer_spc + 'Well ' + iwell + '_spc'\n",
    "        fig.set_size_inches(8, 5)\n",
    "        fig.savefig(fname, dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot well tracer vs NO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-21T22:43:13.762750Z",
     "start_time": "2018-05-21T22:43:12.869924Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "selected_chemical = 'Nitrate'\n",
    "iobs_chemical = GW_chem[GW_chem.loc[:,'Chemical'] == selected_chemical].copy()\n",
    "\n",
    "box_x = [577000, 581000]\n",
    "box_y = [149000, 153000]\n",
    "\n",
    "for iwell in iobs_chemical['WellName'].unique()[:]:\n",
    "#     iwell = '52-D'\n",
    "    print(iwell)\n",
    "    iobs_data_df = iobs_chemical[iobs_chemical.loc[:, 'WellName'] == iwell].copy()\n",
    "    if (iobs_data_df['EASTING'].unique() >= box_x[0] and \\\n",
    "                        iobs_data_df['EASTING'].unique() <= box_x[1] and \\\n",
    "                        iobs_data_df['NORTHING'].unique() >= box_y[0] and \\\n",
    "                        iobs_data_df['NORTHING'].unique() <= box_y[1]):\n",
    "        if iobs_data_df.size >0:\n",
    "            fig, ax1 = plt.subplots(1, 1)  # short hand\n",
    "\n",
    "            plt1 = iobs_data_df.plot(x='DateTime', y='Concentration', linestyle='-',marker='o', \\\n",
    "                                     mfc='none' , markeredgewidth= 0.5, color='k', legend=False, ax=ax1, rot=0)\n",
    "\n",
    "        #         ax1.title('Well ' + iwell)\n",
    "    #         ax1.set_xlim([real_time_index[0], real_time_index[-1]])\n",
    "        #         ax1.set_ylim([0, 1])\n",
    "        #         ax.set_ylim([104.5, 108.5])\n",
    "            unit = iobs_data_df['Unit'].unique()\n",
    "            ax1.set_ylabel('Nitrate ' + '(' + unit[0] + ')', color='k')\n",
    "            ax1.set_xlabel('')\n",
    "            ax1.tick_params('y', colors='k')\n",
    "            ax1.legend(['Nitrate'], frameon=False,\n",
    "                       loc='lower left', bbox_to_anchor=(0, 1))\n",
    "            plt.suptitle('Well ' + iwell)\n",
    "\n",
    "    #         # create another y-scale using the same x axis\n",
    "    #         ax2 = ax1.twinx()\n",
    "    #         plt2 = ax2.plot(real_time_index, itracer, 'r-')\n",
    "    #         ax2.set_ylim([0, 1])\n",
    "    #         ax2.set_ylabel('tracer (-)', color='r')\n",
    "    #         ax2.tick_params('y', colors='r')\n",
    "    #         ax2.legend(['tracer'], frameon=False,\n",
    "    #                    loc='lower right', bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "            fig.tight_layout()\n",
    "            fname = fig_nitrate + 'Well ' + iwell + '_NO3'\n",
    "            fig.set_size_inches(8, 5)\n",
    "            fig.savefig(fname, dpi=300)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot groundwater level contour "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note: for plotting contour surface using `plt.contour(X,Y,Z)`, Z must be shape of (ny, nx)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T04:20:45.728829Z",
     "start_time": "2018-05-14T04:20:45.607686Z"
    }
   },
   "outputs": [],
   "source": [
    "iz = interval_index[-7]\n",
    "fig = plt.figure()\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "# plot contour\n",
    "cf1 = ax1.contourf(x, y, temp_total_head[iz, :,:],\n",
    "                   cmap=plt.cm.jet,\n",
    "                   vmin=100,\n",
    "                   vmax=130,\n",
    "                   extend=\"both\",\n",
    "                   levels=np.arange(100, 130.1, 1)\n",
    "                   )\n",
    "# plot contour lines\n",
    "cf2 = plt.contour(cf1, colors='grey', levels=np.arange(100, 130.1, 1))\n",
    "ax1.set_aspect(\"equal\", \"datalim\")\n",
    "\n",
    "plt.plot(well_screen['Easting'], well_screen['Northing'], 'ko')\n",
    "plt.clabel(cf2, inline = True, fmt = '%3.0d', fontsize = 10)\n",
    "# plt.xlim(42000, 43000)\n",
    "# plt.ylim(9000, 14000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T00:49:31.772431Z",
     "start_time": "2018-05-04T00:49:29.964670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        fig.savefig(fig_name, dpi=600, transparent=True)\n",
    "        plt.close(fig)\n",
    "input_h5.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nersc]",
   "language": "python",
   "name": "conda-env-nersc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 347,
   "position": {
    "height": "369px",
    "left": "3px",
    "right": "20px",
    "top": "691px",
    "width": "309px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
